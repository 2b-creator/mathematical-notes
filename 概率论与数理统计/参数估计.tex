\chapter{参数估计}
在实际应用中，
一个总体\(X\)的分布函数往往含有未知参数或未知参数向量\(\theta\)，
从而可记总体分布函数为\(F(x,\theta)\).
解决实际问题时需要了解未知参数或未知参数向量，
因此可以利用样本提供的信息，
对未知参数或未知参数向量有一个基本的估计.
这就是参数的估计问题.

参数的估计问题分为点估计和区间估计两大类.

在点估计中，我们要构造一个统计量
\(\hat{\theta}=\hat{\theta}(\AutoTuple{X}{n})\)，
然后用\(\hat{\theta}\)去估计\(\theta\).

在区间估计中，我们要构造两个统计量\(\hat{\theta}_1\)和\(\hat{\theta}_2\)，
且\(\hat{\theta}_1<\hat{\theta}_2\)，
然后以区间\([\hat{\theta}_1,\hat{\theta}_2]\)的形式给出对未知参数\(\theta\)的估计.

\section{点估计}
\begin{definition}
设总体\(X\)的分布函数为\(F(x,\theta)\)，
其中\(\theta\)为未知参数.
从总体\(X\)中抽取样本\(\AutoTuple{X}{n}\)，
其观测值为\(\AutoTuple{x}{n}\)，
构造某个统计量\(\hat{\theta}(\AutoTuple{X}{n})\)，
用它的观测值\(\hat{\theta}(\AutoTuple{x}{n})\)来估计未知参数\(\theta\)，
则称\(\hat{\theta}(\AutoTuple{x}{n})\)为\(\theta\)的\DefineConcept{估计值}，
称\(\hat{\theta}(\AutoTuple{X}{n})\)为\(\theta\)的\DefineConcept{估计量}.

定义中估计量或估计值称为\(\theta\)的一个\DefineConcept{点估计}.
点估计量是一个统计量，因而是一个随机变量.
点估计值是一个数.
点估计量或点估计值都可以简记为\(\hat{\theta}\).

若\(\theta=(\AutoTuple{\theta}{k})\)是\(k\)维未知参数向量，则需要构造\(k\)个统计量\[
\hat{\theta}_i = \hat{\theta}_i(\AutoTuple{X}{n}) \quad(i=1,2,\dotsc,k)
\]分别作为\(\AutoTuple{\theta}{k}\)的\DefineConcept{点估计量}.
\end{definition}

由点估计的定义，任何一个统计量都可以作为未知参数\(\theta\)的一个估计量.
但一个估计量是否合理，则需要一定的概率统计理论和意义的基础.
下面介绍两个合乎一定概率统计理论和意义的求估计量的方法.

\subsection{矩估计法}
1900年，卡尔·皮尔逊提出一个替换原则：用样本矩去替换总体矩.
后来人们就称此为“矩估计法”.

设总体\(X\)有分布函数\(F(x,\theta)\)，其中\(\theta\)为一维未知参数.
若\(E(X)\)存在，则\(E(X)=m\)一般是\(\theta\)的函数，即\(m=m(\theta)\).
由此反解出\(\theta=g(m)\)，
再用样本均值\(\overline{X}\)代替\(m\)，
就得到\(\theta\)的一个估计量\(\hat{\theta}=g(\overline{X})\).
这个方法就叫做求估计量的的\DefineConcept{矩估计法}，
\(\hat{\theta}=g(\overline{X})\)叫做\(\theta\)的\DefineConcept{矩估计量}.

例如，若总体\(X \sim U(0,\theta)\)，\(\theta\)未知，
已知来自总体\(X\)的样本\(\AutoTuple{X}{n}\).
由\(m = E(X) = \frac{\theta}{2}\)，得\(\theta=2m\)，
从而\(\theta\)的矩估计量为\(\hat{\theta} = 2\overline{X}\).

矩估计法实际上是一种替代估计，
是用样本均值\(\overline{X}\)替代参数\(\theta=g(m)\)中的总体均值\(m\)，
一般计算都较简单.

矩估计法的合理性在于：
当\(E(X)=m\)，\(D(X)=\sigma^2\)存在时，
由独立同分布大数律，有\(\overline{X} \toP m\).
于是样本容量\(n\)较大时，\(\overline{X}\)的取值与\(m\)会充分接近；
用\(\overline{X}\)替换\(m\)后，
矩估计量\(\hat{\theta}=g(\overline{X})\)的取值会与被估计的参数\(\theta=g(m)\)充分接近，
其估计误差在概率意义下会充分小.
因而矩估计量是\(\theta\)的一个较合理的估计量.

一般地，若总体\(X\)的分布函数\(F(x,\vb{\theta})\)中，
\(\vb{\theta}=(\AutoTuple{\theta}{k})\)为\(k\)维未知参数，
且\(X\)的直到\(k\)阶原点矩均存在，则有\[
	\def\m#1{m_{#1} = E(X\ifthenelse{\equal{#1}{1}}{}{^{#1}}) = m_{#1}(\AutoTuple{\theta}{k})}
	\left\{ \begin{array}{l}
		\m{1}, \\
		\m{2}, \\
		\hdotsfor{1} \\
		\m{k}. \\
	\end{array} \right.
\]
从上述方程组反解出\(\AutoTuple{\theta}{k}\)，为\(\AutoTuple{m}{k}\)的函数，即\[
	\def\g#1{\theta_{#1}=g_{#1}(\AutoTuple{m}{k})}
	\left\{ \begin{array}{l}
		\g{1}, \\
		\g{2}, \\
		\hdotsfor{1} \\
		\g{k}. \\
	\end{array} \right.
\]
再用\(r\)阶样本原点矩\(A_r = \frac{1}{n} \sum_{i=1}^n{X_i^r}\)，
替代上式中的\(m_r\ (r=1,2,\dots,k)\)，
则得到\(\AutoTuple{\theta}{k}\)的矩估计量，即\[
	\def\g#1{\hat{\theta}_{#1}=g_{#1}(\AutoTuple{A}{k})}
	\left\{ \begin{array}{l}
		\g{1}, \\
		\g{2}, \\
		\hdotsfor{1} \\
		\g{k}. \\
	\end{array} \right.
\]

\begin{example}
设总体\(X\)服从任何分布，且\(X\)的期望与方差均存在.
记\(E(X)=\mu\)，\(D(X)=\sigma^2\)，\(\mu\)、\(\sigma^2\)是两个未知参数.
\(\AutoTuple{X}{n}\)为样本.
求\(\mu\)和\(\sigma^2\)的矩估计量.
\begin{solution}
因为有两个未知参数\(\mu\)和\(\sigma^2\)，故有\[
	\left\{ \begin{array}{l}
		m_1=E(X)=\mu, \\
		m_2=E(X^2)=D(X)+[E(X)]^2=\sigma^2+\mu^2.
	\end{array} \right.
\]
解得\[
	\left\{ \begin{array}{l}
		\mu=m_1, \\
		\sigma^2=m_2-m_1^2.
	\end{array} \right.
\]
再用样本一阶、二阶原点矩代替对应总体原点矩，可得矩估计量为\[
	\left\{ \begin{array}{l}
		\hat{\mu}=\overline{X}, \\
		\hat{\sigma}^2=A_2-\overline{X}^2=B_2.
	\end{array} \right.
\]
\end{solution}
\end{example}

\begin{theorem}
若\(\eta = g(\theta)\)是未知参数\(\theta\)的连续函数（即\(\eta\)也是一个未知参数），
那么\(\eta\)的矩估计量为\(\hat{\eta}=g(\hat{\theta})\)，
其中\(\hat{\theta}\)为\(\theta\)的矩估计量.
\end{theorem}

\begin{remark}
矩估计量可以不唯一.

比如，若总体\(X\)服从自然指数分布族分布，
因为总体均值\(m\)的矩估计量为\(\overline{X}\)，
这时总体方差\(\sigma^2 = V(m)\)是\(m\)的函数，
则\(\sigma^2\)的矩估计量可以是\(\hat{\sigma}^2 = V(\overline{X})\)，
也可以是\(\hat{\sigma}^2 = B_2\).
足见参数\(\theta\)的矩估计量可以是不唯一的.
\end{remark}

\begin{example}
总体\(X \sim B(N,p)\)，\(N\)已知，而\(p\)未知.
\(\AutoTuple{X}{n}\)为样本.
\begin{enumerate}
	\item 求参数\(p\)的矩估计量；
	\item 求总体方差\(\sigma^2\)的矩估计量并将其表示为\(\overline{X}\)的函数.
\end{enumerate}
\begin{solution}
\begin{enumerate}
	\item 总体期望为\(m=E(X)=Np\)，故\(p=\frac{m}{N}\)，
	于是用\(\overline{X}\)代\(m\)，得\(p\)的矩估计量为\[
		\hat{p}=\frac{\overline{X}}{N}.
	\]
	\item 总体方差\(\sigma^2=D(X)=Np(1-p)=Np-Np^2=m-\frac{m^2}{N}\)，
	则用\(\overline{X}\)代\(m\)，得\(\sigma^2=V(m)\)的矩估计量为\[
		\hat{\sigma}^2=V(\overline{X})=\overline{X}-\frac{\overline{X}^2}{N}.
	\]
\end{enumerate}
\end{solution}
\end{example}

\begin{example}
设总体\(X \sim U(\theta_1,\theta_2)\)，其中\(\theta_1,\theta_2\)是两个未知参数.
\(\AutoTuple{X}{n}\)是样本，求\(\theta_1,\theta_2\)的矩估计量.
\begin{solution}
因为\(m\)和\(\sigma^2\)的矩估计量分别为\(\overline{X}\)和\(B_2\)，
所以只需把\(\theta_1\)和\(\theta_2\)表示为\(m\)和\(\sigma^2\)的函数.
又因为\[
	\begin{cases}
		m = E(X) = \frac{\theta_1+\theta_2}{2}, \\
		\sigma^2 = D(X) = \frac{(\theta_2-\theta_1)^2}{12},
	\end{cases}
\]
故有\[
	\begin{cases}
		\theta_1+\theta_2 = 2m, \\
		\theta_2-\theta_1 = 2 \sqrt{3\sigma^2}.
	\end{cases}
\]
解得\[
	\begin{cases}
		\theta_1 = m - \sqrt{3\sigma^2}, \\
		\theta_2 = m + \sqrt{3\sigma^2}.
	\end{cases}
\]
代入\(m\)及\(\sigma^2\)的矩估计量\(\overline{X}\)及\(B_2\)，
得\(\theta_1,\theta_2\)的矩估计量为\[
	\begin{cases}
		\hat{\theta}_1 = \overline{X} - \sqrt{3 B_2}, \\
		\hat{\theta}_2 = \overline{X} + \sqrt{3 B_2}.
	\end{cases}
\]
\end{solution}
\end{example}

由于矩估计法原则上不要求总体的分布情况，
因此未能充分利用已知分布的信息，
在样本容量\(n\)较小时估计值可能误差较大.

\subsection{极大似然估计法}
设总体\(X\)是离散型随机变量，分布律为\(P(X=x)=p(x,\theta)\)，
其中\(\theta\)是未知参数.
当样本\(\AutoTuple{X}{n}\)得到一组观测值\(\AutoTuple{x}{n}\)时，
由样本的独立同分布性，记样本取得这组观测值的概率为
\begin{align*}
	L(\theta)
	&\defeq P\left(\bigcap_{i=1}^n(X_i=x_i)\right) \\
	&= \prod_{i=1}^n P(X_i=x_i) \\
	&= \prod_{i=1}^n p(x_i,\theta),
\end{align*}
称函数\(L(\theta)\)为“未知参数\(\theta\)的\DefineConcept{似然函数}”.

极大似然估计法的思想是：
随机试验有若干个可能结果，如果在一次试验中某一结果出现了，
由小概率事件原理，我们便自然认为这一结果出现的概率较大，
从而可以认为这一结果是所有可能结果中出现概率最大的一个.
因此\(p\)应该这样估计，即选择\(\hat{p}\)使得上述观测值出现的概率最大.
也就是使\(L(\hat{p})\)为\(L(p)\)的最大值.
而求\(L(p)\)的最大值点\(\hat{p}\)，可由方程\[
	\dv{p} L(p) = 0
\]解得.

\begin{definition}
设总体\(X\)仅含一个未知参数，
并且总体的分布律或密度函数已知.
假设我们已经取得一组样本观测值\(\AutoTuple{x}{n}\).
若存在\(\hat{\theta}\)使得\[
	L(\hat{\theta}) = \max_\theta L(\theta),
\]
则称\(\hat{\theta} = \hat{\theta}(\AutoTuple{x}{n})\)是
“\(\theta\)的\DefineConcept{极大似然估计值}”，
而统计量\(\hat{\theta}(\AutoTuple{X}{n})\)称为
“\(\theta\)的\DefineConcept{极大似然估计量}”.
\end{definition}

对于连续型总体\(X\)，\(X\)的概率密度函数为\(f(x,\theta)\)，
其中\(\theta\)是未知参数.若取得样本观测值\(\AutoTuple{x}{n}\)，
则因为随机变量\(X_i\)落在点\(x_i\)的邻域
（设其长度为\(\increment x_i\)）
内的概率近似于\[
	f(x_i,\theta) \increment x_i
	\quad(i=1,2,\dotsc,n),
\]
则样本\((\AutoTuple{X}{n})\)落在样本观测值\((\AutoTuple{x}{n})\)邻域的概率近似为\[
	\prod_{i=1}^n f(x_i,\theta) \increment x_i.
\]
那么\(\theta\)的估计值\(\hat{\theta}\)
应使概率\(\prod_{i=1}^n f(x_i,\theta) \increment x_i\)达到最大值.
但因为\(\increment x_i\)与\(\theta\)无关，
故只要使\(\prod_{i=1}^n{f(x_i,\theta)}\)达到最大值即可.
此时，记\[
	L(\theta) \defeq \prod_{i=1}^n{f(x_i,\theta)},
\]
仍然称\(L(\theta)\)为似然函数.

\begin{definition}
用于解出使\(L(\theta)\)取得最大值的极大似然估计值\(\hat{\theta}\)的方程\[
	\dv{\theta} L(\theta) = 0
\]称为\DefineConcept{似然方程}.

由于\(\ln L\)和\(L\)在相同的\(\theta\)处取得最大值，有时候也采用方程\[
	\dv{\theta} \ln L(\theta) = 0,
\]
以解出极大似然估计值\(\hat{\theta}\)，
并称之为\DefineConcept{对数似然方程}.
\end{definition}

当总体\(X\)服从单峰分布\footnote{%
“单峰分布”是指密度函数图像或其概率分布图只有一个峰的分布.
除均匀分布以外，常见分布都是单峰分布.}时，
若似然方程或对数似然方程有解，
则其解就是\(\theta\)的极大似然估计值.

\begin{example}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P196. 例8.6
设总体\(X \sim B(N,p)\)，
其中\(N\)已知，
\(\AutoTuple{x}{n}\)为样本观测值，
求\(p\)及\(m=E(X)\)的极大似然估计.
\begin{solution}
总体\(X\)的分布律为\[
	f(x,p)
	= C_N^x p^x (1-p)^{N-x},
	\quad x=0,1,\dots,N.
\]
故似然函数为\[
	L(p)
	= \prod_{i=1}^n f(x_i,p)
	= \prod_{i=1}^n C_N^{x_i} p^{x_i} (1-p)^{N-x_i}
	= p^{\sum_{i=1}^n x_i}
		(1-p)^{nN-\sum_{i=1}^n x_i}
		\prod_{i=1}^n C_N^{x_i},
\]
取对数，得\[
	\ln L(p)
	= \sum_{i=1}^n x_i \ln p
	+ \left(nN - \sum_{i=1}^n{x_i}\right) \ln(1-p)
	+ \sum_{i=1}^n \ln C_N^{x_i}.
\]
求导得\[
	\dv{p} \ln L(p)
	= \frac{1}{p} \sum_{i=1}^n{x_i}
	- \frac{1}{1-p} \left(nN - \sum_{i=1}^n{x_i}\right).
\]
建立对数似然方程\(\dv{p} \ln L(p) = 0\)，
解得\(p\)的极大似然估计值为\[
	\hat{p}
	= \frac{1}{nN} \sum_{i=1}^n x_i
	= \frac{\overline{x}}{N},
\]
其中\(\overline{x}=\frac{1}{n}\sum_{i=1}^n{x_i}\).
而\(p\)的极大似然估计量为\[
	\hat{p} = \frac{\overline{X}}{N}.
\]

又因为\(m=E(X)=Np\)，
故\(m\)的极大似然估计值为\[
	\hat{m} = N\hat{p} = \overline{x},
\]
而\(m\)的极大似然估计量为\[
	\hat{m} = \overline{X}.
\]
\end{solution}
\end{example}

注意当\(N\)已知时，二项分布\(B(N,p)\)属于自然指数分布族.
这个例子关于“\(m\)的极大似然估计量为\(\overline{X}\)”的结论
对一般的自然指数分布族也成立.

\begin{theorem}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P197. 定理8.1
若总体\(X\)服从自然指数分布族分布，
则均值参数\(m=E(X)\)的极大似然估计量为样本均值，
即\[
	\hat{m}=\overline{X}.
\]
\begin{proof}
总体\(X\)的概率分布或密度函数为\[
	f(x,\theta)=e^{\theta x - \phi(\theta)} h(x),
\]
取得样本观测值\(\AutoTuple{x}{n}\)，
注意\(\theta\)是\(m\)的函数\(\theta(m)\)，故得似然函数\[
	L(m) = \prod_{i=1}^n e^{\theta(m) x_i -\phi[\theta(m)]} h(x_i)
	= \exp\left\{
		\theta(m) \sum_{i=1}^n[x_i - n \phi(\theta(m))]
		\prod_{i=1}^n{h(x_i)}
	\right\},
\]\[
	\ln L(m)
	= \theta(m) \sum_{i=1}^n x_i - n \phi[\theta(m)]
	+ \ln \prod_{i=1}^n{h(x_i)},
\]

令\[
	\dv{m} \ln L(m)
	= \theta'(\theta) \sum_{i=1}^n{x_i}
	- n \phi'[\theta(m)] \theta'(m) = 0,
\]
由于\(\phi'(\theta) = m\)，
\(\dv{m}{\theta} = \phi''(\theta) = D(X) > 0\)，
从而\(\theta'(m) = \dv{\theta}{m} > 0\)，所以\[
	\sum_{i=1}^n{x_i} - nm = 0.
\]
可见\(m\)的极大似然估计值为\[
	\hat{m} = \overline{x},
\]
其极大似然估计量为\[
	\hat{m} = \overline{X}.
	\qedhere
\]
\end{proof}
\end{theorem}

这样，对自然指数分布族，
均值参数\(m\)的矩估计量与极大似然估计量都是样本均值\(\overline{X}\).
而且，当总体方差函数\(\sigma^2=V(m)\)有单值反函数时，
方差函数\(V(m)\)的极大似然估计量为\(V(\overline{X})\).
不难证明，在常见的自然指数分布族分布中，除去二项分布外，
它们的方差函数\(V(m)\)在其均值空间中都有单值反函数.
比如，对几何分布，\(m=E(X)=\frac{1}{p}\)，\(V(m)=D(X)=\frac{q}{p^2}=m^2-m\)，
在\(m>1\)时有单值反函数，
故\(V(m)=m^2-m\)的极大似然估计为\(V(\overline{X})=\overline{X}^2 - \overline{X}\).

当总体\(X\)的分布中含有多个未知参数，
即\(\vb{\theta}=(\AutoTuple{\theta}{k})\)时，
似然函数为\[
	L(\vb{\theta})
	= L(\AutoTuple{\theta}{k}).
\]
于是我们有若干个对数似然方程，
需要建立对数似然方程组\[
	\def\g#1{\pdv{\theta_{#1}} \ln L(\vb{\theta}) = 0}
	\left\{ \def\arraystretch{1.5} \begin{array}{l}
		\g{1}, \\
		\g{2}, \\
		\hdotsfor{1} \\
		\g{k}. \\
	\end{array} \right.
\]
若对数似然方程组有解\(\hat{\vb\theta}=(\AutoTuple{\hat{\theta}}{k})\)，
则它们分别是\(\vb\theta=(\AutoTuple{\theta}{k})\)的极大似然估计值.

\begin{example}
设总体\(X \sim N(\mu,\sigma^2)\)，
其中\(\mu\)和\(\sigma^2\)都是未知参数.
\(\AutoTuple{x}{n}\)为样本观测值.
求\(\mu\)和\(\sigma^2\)的极大似然估计.
\begin{solution}
似然函数为\begin{align*}
	L(\mu,\sigma^2)
	&= \prod_{i=1}^n f(x_i,\mu,\sigma^2)
	= \prod_{i=1}^n
		\frac{1}{\sqrt{2\pi}\sigma}
		e^{-\frac{(x_i-\mu)^2}{2\sigma^2}} \\
	&= (2\pi\sigma^2)^{-\frac{n}{2}}
		\exp[-\frac{1}{2\sigma^2} \sum_{i=1}^n{(x_i-\mu)^2}],
\end{align*}
取对数，得\[
	\ln L(\mu,\sigma^2)
	= -\frac{n}{2} (\ln{2\pi} + \ln \sigma^2)
	- \frac{1}{2\sigma^2} \sum_{i=1}^n{(x_i-\mu)^2},
\]
从而有\[
	\left\{ \begin{array}{l}
		\pdv{\mu} \ln L(\mu,\sigma^2) = \frac{1}{\sigma^2} \sum_{i=1}^n{(x_i-\mu)} = 0, \\
		\pdv{(\sigma^2)} \ln L(\mu,\sigma^2) = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^n{(x_i-\mu)^2} = 0.
	\end{array} \right.
\]
解得\(\mu\)及\(\sigma^2\)的极大似然估计值为\[
	\left\{ \begin{array}{l}
	\hat{\mu} = \overline{x}, \\
	\hat{\sigma^2} = \frac{1}{n} \sum_{i=1}^n{(x_i-\overline{x})^2} = b_2,
	\end{array} \right.
\]
而其极大似然估计量为\[
	\left\{ \begin{array}{l}
		\hat{\mu} = \overline{X}, \\
		\hat{\sigma^2} = \frac{1}{n} \sum_{i=1}^n{(X_i-\overline{X})^2} = B_2.
	\end{array} \right.
\]
\end{solution}
\end{example}
由上可知，当总体\(X \sim N(\mu,\sigma^2)\)时，
\(\mu\)和\(\sigma^2\)的矩估计量与极大似然估计量是相同的.

需要指出的是，当似然方程或对数似然方程无解时，应从定义考虑求极大似然估计，
即选择\(\hat{\theta}\)使得\(L(\hat{\theta})=\max L(\theta)\).

\begin{example}
设总体\(X \sim U(0,\theta)\)，\(\theta>0\)是未知参数，
\(\AutoTuple{x}{n}\)是样本观测值.
求\(\theta\)的极大似然估计.
\begin{solution}
\(X\)的密度函数为\[
f(x,\theta) = \left\{ \begin{array}{cl}
\theta^{-1}, & 0 \leq x \leq \theta, \\
0, & \text{其他},
\end{array} \right.
\]而似然函数为\[
L(\theta) = \prod_{i=1}^n{f(x_i,\theta)} = \theta^{-n},
\quad x_i \in [0,\theta], \quad i=1,2,\dotsc,n.
\]由于似然方程\(\dv{\theta} L(\theta) = -n\theta^{-1-n} = 0\)在\(\theta>0\)无解.
所以应该考虑似然估计的定义.
因为似然函数\(L(\theta)=\theta^{-n}\)在\(\theta>0\)时为\(\theta\)的单调递减函数，
\(\theta\)越小则\(L(\theta)\)越大；但另一方面，\(x_i\in[0,\theta]\)，
故有\(\max_{1 \leq i \leq n} x_i \in [0,\theta]\).
故当\(\hat{\theta}=\max_{1 \leq i \leq n} x_i\)时，
\(L(\hat{\theta})=\max L(\theta)\).
所以，\(\theta\)的极大似然估计值为\[
\hat{\theta} = \max_{1 \leq i \leq n} x_i,
\]而其极大似然估计量为\[
\max_{1 \leq i \leq n} X_i.
\]
\end{solution}
\end{example}

\section{估计量的评选标准}
我们已经知道，任何一个统计量都可以作为一个未知参数的估计量.
对于同一参数的多种估计量，采用哪一种更好呢？这就需要一定的标准来做评价.

\subsection{无偏性标准}
\begin{definition}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P200. 定义8.3
若未知参数\(\theta\)的估计量\(\hat{\theta}=\hat{\theta}(\AutoTuple{X}{n})\)满足\[
	E(\hat{\theta})=\theta,
\]
则称“\(\hat{\theta}\)是参数\(\theta\)的\DefineConcept{无偏估计量}”.
否则称“\(\hat{\theta}\)是参数\(\theta\)的\DefineConcept{有偏估计量}”.

对有偏估计量\(\hat{\theta}\)，
我们把\[
	E(\hat{\theta}) - \theta
\]称为\(\hat{\theta}\)的\DefineConcept{偏差}（bias），
记作\(b(\hat{\theta})\).

若样本容量\(n\to\infty\)时，有\(b(\hat{\theta})\to0\)，
则称“\(\hat{\theta}\)是\(\theta\)的\DefineConcept{渐进无偏估计量}”.
\end{definition}

\begin{example}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P200. 例8.9
设总体\(X\)服从任何分布，
且\(E(X)=\mu\)，\(E(X^k)=m_k\)，\(D(X)=\sigma^2\).
\(\AutoTuple{X}{n}\)是样本.
证明：样本均值\(\overline{X}\)、样本\(k\)阶原点矩\(A_k\)和样本方差\(S^2\)分别是
\(\mu\)、\(m_k\)和\(\sigma^2\)的无偏估计量.
\begin{proof}
因为\(E(A_k)
= E\left(\frac{1}{n} \sum_{i=1}^n X_i^k\right)
= \frac{1}{n} \sum_{i=1}^n E(X_i^k)
= E(X^k)
= m_k\)，
所以\(A_k\)是\(m_k\)的无偏估计量.

特别地，
由\cref{equation:统计量.均值-1阶原点矩的关系}，
有\(\overline{X} = A_1\)，
于是\(E(\overline{X})
= E(A_1)
= m_1
= \mu\)，
因此，\(\overline{X}\)是\(\mu\)的无偏估计量.

由\cref{equation:统计量.2阶中心距-2阶原点矩-均值的关系}
有\(B_2 = A_2 - \overline{X}^2\)；
由\cref{equation:统计量.方差-2阶中心距的关系}
有\(S^2 = \frac{n}{n-1} B_2\)；
所以\[
	E(S^2)
	= E\left(\frac{n}{n-1} B_2\right)
	= \frac{n}{n-1} E(A_2-\overline{X}^2)
	= \frac{n}{n-1}[E(A_2)-E(\overline{X}^2)].
\]
由于\(E(A_2)
= E(X^2)
= D(X) + [E(X)]^2
= \sigma^2 + \mu^2\)，
所以\[
	E(\overline{X}^2)
	= D(\overline{X}) + [E(\overline{X})]^2
	= \frac{\sigma^2}{n} + \mu^2,
\]
那么有\[
	E(S^2)
	= \frac{n}{n-1} \left(\sigma^2 + \mu^2 - \frac{\sigma^2}{n} - \mu^2\right)
	= \sigma^2.
	\qedhere
\]
\end{proof}
\end{example}

\begin{example}
设总体\(X\)服从任何分布，
且\(E(X)=\mu\in[0,+\infty)\)，
\(D(X)=\sigma^2\in(0,+\infty)\).
\(\AutoTuple{X}{n}\)是样本.
证明：样本2阶中心矩\(B_2\)是\(\sigma^2\)的渐进无偏估计量.
\begin{proof}
因为\[
	E(B_2)
	= E\left(\frac{n-1}{n} S^2\right)
	= \frac{n-1}{n} E(S^2)
	= \left(1-\frac{1}{n}\right) \sigma^2
	< \sigma^2,
\]
所以\(B_2\)是\(\sigma^2\)的有偏估计量.
又因为\[
	\lim_{n\to\infty} [E(B_2) - \sigma^2]
	= -\lim_{n\to\infty} \frac{\sigma^2}{n}
	= 0,
\]
所以\(B_2\)是\(\sigma^2\)的渐进无偏估计量.
\end{proof}
\end{example}

\begin{example}
设\(X_1,X_2\)是来自总体\(N(\mu,\sigma^2)\)的简单随机样本，其中\(\sigma\ (\sigma>0)\)是未知参数.
若\(\hat{\sigma} = a\abs{X_1-X_2}\)是\(\sigma\)的无偏估计量，求\(a\)的取值.
\begin{solution}
由正态分布的可加性，有\(X_1-X_2 \sim N(0,2\sigma^2)\).
令\(Y = X_1-X_2\)，则\(Y\)的概率密度为\[
f(y) = \frac{1}{\sqrt{2\pi} \cdot \sqrt{2} \sigma} \exp(-\frac{y^2}{2 \cdot 2 \sigma^2}).
\]从而\[
	E(\hat{\sigma}) = E(a \abs{Y})
	= a \int_{-\infty}^{+\infty} \abs{y} f(y) \dd{y}
	= a \frac{2 \sigma}{\sqrt{\pi}}.
\]
因为\(\hat{\sigma} = a\abs{X_1-X_2}\)是\(\sigma\)的无偏估计量，
所以\(E(\hat{\sigma}) = \sigma\)，代入上式，解得\(a = \sqrt{\pi}/2\).
\end{solution}
\end{example}

\subsection{有效性标准}
\begin{definition}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P201. 定义8.4
设\(\hat{\theta}_1\)和\(\hat{\theta}_2\)是\(\theta\)的两个无偏估计量.
若\[
	D(\hat{\theta}_1) \leq D(\hat{\theta}_2),
\]
则称“\(\hat{\theta}_1\)比\(\hat{\theta}_2\)更\DefineConcept{有效}”.
\end{definition}

\begin{example}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P202. 例8.10
设总体服从任何分布，\(\mu=E(X)\)，\(\sigma^2=D(X)\)是未知参数.
\(\AutoTuple{X}{n}\)是样本，
\(\AutoTuple{a}{n}\)是常数.
证明：
\begin{enumerate}
	\item 若\(\sum_{i=1}^n a_i=1\)，
	则\(\sum_{i=1}^n a_i X_i\)是\(\mu\)的无偏估计量；

	\item 在所有可能的\(\sum_{i=1}^n a_i X_i\)中，
	\(\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i\)是最有效的无偏估计量.
\end{enumerate}
%TODO
\end{example}

\subsection{一致性标准}
容易看出，估计量\(\hat{\theta}(\AutoTuple{X}{n})\)与样本容量\(n\)有关，
故可记作\(\hat{\theta}(n)\).
对\(\hat{\theta}(n)\)的一个自然的要求是，
当\(n\)充分大时，\(\hat{\theta}(n)\)的取值与\(\theta\)的误差应充分小，
即估计量\(\hat{\theta}(n)\)的取值应稳定在参数\(\theta\)的一个充分小的邻域内.

\begin{definition}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P202. 定义8.5
\(\hat{\theta}(n)\)是\(\theta\)的估计量，若\[
	\hat{\theta}(n) \toP \theta,
\]
则称“\(\hat{\theta}(n)\)是\(\theta\)的\DefineConcept{一致估计量}或\DefineConcept{相合估计量}”.
\end{definition}

由\hyperref[theorem:极限定理.大数律.独立同分布大数律]{独立同分布大数律}，
可知当总体\(X\)有\(D(X^k)\)存在时，
则样本\(k\)阶原点矩\(A_k \toP E(X^k) = m_k\)，
也就是说，样本\(k\)阶原点矩是总体\(k\)阶原点矩的一致估计量.
特别地，样本均值\(\overline{X}\)是总体数学期望\(\mu = E(X)\)的一致估计量.

此外，当样本方差\(S^2\)的方差\(D(S^2) \to 0\ (n\to\infty)\)时，
由\cref{theorem:极限定理.大数律.随机变量序列依概率收敛的充分条件}
有\(S^2 - E(S^2) = S^2 - \sigma^2 \toP 0\)，
从而样本方差\(S^2\)是总体方差\(\sigma^2\)的一致估计量.

\subsection{均方误差标准}
\begin{definition}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P203. 定义8.6
对于总体\(X\)的未知参数\(\theta\)，\(\hat{\theta}\)是\(\theta\)的估计量.
把\[
	M(\hat{\theta}) = E(\hat{\theta} - \theta)^2
\]称为“\(\hat{\theta}\)关于\(\theta\)的\DefineConcept{均方误差}”.
\end{definition}

\begin{definition}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P203. 定义8.6
设\(\hat{\theta}_1\)和\(\hat{\theta}_2\)都是\(\theta\)的估计量，
\(M(\hat{\theta}_1)\)和\(M(\hat{\theta}_2)\)
分别是\(\hat{\theta}_1\)和\(\hat{\theta}_2\)关于\(\theta\)的均方误差.
若\[
	M(\hat{\theta}_1) \leq M(\hat{\theta}_2),
\]
则称“\(\hat{\theta}_1\)在均方误差下比\(\hat{\theta}_2\)更\DefineConcept{有效}”.
\end{definition}

\begin{theorem}\label{theorem:参数估计.估计量的均方误差-方差-偏差的关系}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P203. 定理8.2
\(M(\hat{\theta}) = D(\hat{\theta}) + b^2(\hat{\theta})
= D(\hat{\theta}) + [E(\hat{\theta}) - \theta]^2.\)
\begin{proof}
直接计算得\begin{align*}
	M(\hat{\theta})
	&= E(\hat{\theta} - \theta)^2
	= E\left\{
		[\hat{\theta} - E(\hat{\theta})]
		+ [E(\hat{\theta}) - \theta]
	\right\}^2 \\
	&= E[\hat{\theta} - E(\hat{\theta})]^2
	+ [E(\hat{\theta}) - \theta]^2
	+ 2[E(\hat{\theta}) - \theta][E(\hat{\theta}) - E(\hat{\theta})] \\
	&= D(\hat{\theta}) + [E(\hat{\theta}) - \theta]^2
	= D(\hat{\theta}) + b^2(\hat{\theta}).
	\qedhere
\end{align*}
\end{proof}
\end{theorem}
从\cref{theorem:参数估计.估计量的均方误差-方差-偏差的关系} 可以看出，
若\(\hat{\theta}\)是\(\theta\)的无偏估计量，
则偏差\(b(\hat{\theta})=0\)，
从而\(M(\hat{\theta})=D(\hat{\theta})\).
这样的\(\theta\)的无偏估计量
\(\hat{\theta}_1\)与\(\hat{\theta}_2\)之间均方误差的比较就成了方差的比较.
所以\emph{有效性标准}是\emph{均方误差标准}的特殊情况.
但用均方误差可以比较两个有偏估计量之间，
或一个无偏估计量与一个有偏估计量之间的有效性.

\begin{example}
%@see: 《概率论与数理统计》（陈鸿建、赵永红、翁洋） P204. 例8.11
设总体\(X \sim N(\mu,\sigma^2)\)，其中\(\mu\)和\(\sigma^2\)是未知参数.
比较\(\sigma_1^2=S^2\)和\(\sigma_2^2=B_2\)这两个估计量关于\(\sigma^2\)的均方误差.
\begin{solution}
因为\(E(\hat{\sigma}_1^2)
= E(S^2)
= \sigma^2\)，
所以\[
	M(\hat{\sigma}_1^2)
	= M(S^2)
	= D(S^2).
\]
但是由抽样分布定理可知\[
	\frac{(n-1) S^2}{\sigma^2}
	\sim
	\x(n-1),
\]
于是\[
	D\left[\frac{(n-1) S^2}{\sigma^2}\right]
	= \frac{(n-1)^2}{\sigma^4} D(S^2)
	= 2(n-1),
\]
故得到\[
	M(\hat{\sigma}_1^2)
	= D(S^2)
	= \frac{2\sigma^4}{n-1}.
\]
又因为\[
	E(\hat{\sigma}_2^2)
	= E(B_2)
	= E\left(\frac{n-1}{n} S^2\right)
	= \frac{n-1}{n} \sigma^2,
\]\[
	D(\hat{\sigma}_2^2)
	= D(B_2)
	= D\left(\frac{n-1}{n} S^2\right)
	= \frac{(n-1)^2}{n^2} D(S^2)
	= \frac{2(n-1)}{n^2} \sigma^4,
\]
故\[
	M(\hat{\sigma}_2^2)
	= D(\hat{\sigma}_2^2) + b^2(\hat{\sigma}_2^2)
	= \frac{2n-1}{n^2} \sigma^4.
\]
由于\(\frac{2}{n-1} > \frac{2n-1}{n^2}\)，所以\[
	M(\hat{\sigma}_2^2) < M(\hat{\sigma}_1^2).
\]
由此可见，在均方误差意义下，\(B_2\)比\(S^2\)更有效.
\end{solution}
\end{example}

\section{区间估计}
从总体\(X\)中取得样本观测值后，由参数的点估计方法，可以求得未知参数\(\theta\)的估计值.
但由于样本的随机性，我们知道一般这个估计值与参数的真实值\(\theta\)有误差，但不知道误差在什么范围内.
因而我们希望能够找出一个区间，使得参数\(\theta\)落入该区间的概率是可以计算的.
这样我们就能在一定的可靠程度下得出估计值可能的最大误差.
这就是区间估计的思想.

\subsection{置信区间}
\begin{definition}
设总体\(X\)的分布函数\(F(x,\theta)\)中含有未知参数\(\theta\).
\(\AutoTuple{X}{n}\)是来自总体\(X\)的样本.
\(\hat{\theta}_1=\hat{\theta}_1(\AutoTuple{X}{n})\)%
和\(\hat{\theta}_2=\hat{\theta}_2(\AutoTuple{X}{n})\)是两个统计量.
若对给定的概率\(1-\alpha\ (0<\alpha<1)\)，有\[
	P(\hat{\theta}_1<\theta<\hat{\theta}_2)=1-\alpha,
\]
则称随机区间\((\hat{\theta}_1,\hat{\theta}_2)\)为
“参数\(\hat{\theta}\)的置信度为\(1-\alpha\)的\DefineConcept{置信区间}”.
\(\hat{\theta}_1\)称为\DefineConcept{置信下限}.
\(\hat{\theta}_2\)称为\DefineConcept{置信上限}.
\(1-\alpha\)称为\DefineConcept{置信度}或\DefineConcept{置信水平}.

若给定样本观测值\(\AutoTuple{x}{n}\)，
代入得到的实数区间\((\hat{\theta}_1,\hat{\theta}_2)\)也叫置信区间.
要加以区分时，它们分别叫做\DefineConcept{随机置信区间}和\DefineConcept{实数置信区间}.
\end{definition}

通常\(\alpha\)很小，使得\(\theta\)落在这个区间外的事件是一个小概率事件，
比如\(\alpha\)取0.01、0.05等.一般来说，若\(\alpha\)越小，
则\(\theta\)落在\((\hat{\theta}_1,\hat{\theta}_2)\)内的可靠程度越大，
但这个区间也就越宽，从而估计的误差也就越大.

由定义，随机置信区间的意义是\(\theta\)落入\((\hat{\theta}_1,\hat{\theta}_2)\)内的概率为\(1-\alpha\).
而实数置信区间的意义是：当样本容量\(n\)固定时，若我们做\(N\)次抽样，
第\(k\)次得到的样本观测值\(x_{1k},x_{2k},\dotsc,x_{nk}\)，
这样随机地得到\(N\)个实数置信区间\((\hat{\theta}_{1k},\hat{\theta}_{2k})\ (k=1,2,\dots,N)\)；
而这\(N\)个区间中，有的包含参数\(\theta\)的真值，有的不包含.
但当置信度为\(1-\alpha\)时，
这\(N\)个区间中包含有参数\(\theta\)的真值的区间大约占\(100(1-\alpha)\%\).

\subsection{确定置信区间的基本方法步骤}
\begin{enumerate}
	\item 设\(\AutoTuple{X}{n}\)是来自总体\(X\)的样本，
	取一个\(\theta\)的较优的点估计量\(\hat{\theta}=\hat{\theta}(\AutoTuple{X}{n})\).
	习惯上，可取\(\theta\)的无偏估计量；
	\item 由\(\hat{\theta}\)出发，找一个样本函数，\(W=W(\hat{\theta},\theta)\)，
	其分布已知，且只含一个未知参数\(\theta\)，\(W\)的分位点应能从表中查到；
	\item 查表求得\(W\)的\(\frac{\alpha}{2}\)和\(1-\frac{\alpha}{2}\)
	分位点\(W_{\frac{\alpha}{2}}\)和\(W_{1-\frac{\alpha}{2}}\)，
	使得有\(P(W_{\frac{\alpha}{2}}<W<W_{1-\frac{\alpha}{2}})=1-\alpha\)；
	\item 从不等式\(W_{\frac{\alpha}{2}}<W<W_{1-\frac{\alpha}{2}}\)
	解得等价的不等式\(\hat{\theta}_1 < \theta < \hat{\theta}_2\)，
	这时有\(P(\hat{\theta}_1 < \theta < \hat{\theta}_2) = 1-\alpha\).
	于是，\((\hat{\theta}_1,\hat{\theta}_2)\)就是\(\theta\)的置信度为\(1-\alpha\)的随机置信区间；
	\item 若还取得样本观测值\(\AutoTuple{x}{n}\)，代入可得实数置信区间.
\end{enumerate}

这样求得的置信区间称为\DefineConcept{双侧置信区间}.

我们也可根据需要类似地求得\DefineConcept{单侧置信区间}，
使\(P(\theta<\hat{\theta}_2)=1-\alpha\)或\(P(\hat{\theta}_1<\theta)=1-\alpha\).

\subsection{一个正态总体下的参数的置信区间}
本小节中，设总体\(X \sim N(\mu,\sigma^2)\)，\(\AutoTuple{X}{n}\)是来自总体\(X\)的样本.
\begin{example}
已知\(\sigma^2=\sigma_0^2\)，
则总体均值\(\mu\)的置信区间为\[
	\left( \overline{X} - u_{1-\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}},
	\overline{X} + u_{1-\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}} \right).
\]
\begin{proof}
\def\U{\frac{\overline{X}-\mu}{\sigma_0 / \sqrt{n}}}
由于\(\overline{X}\)是\(\mu\)的无偏估计，故可取样本函数\(U=\U\)，且\[
	U \sim N(0,1).
\]

对于给定的置信度\(1-\alpha\)，
由\(P(u_{\frac{\alpha}{2}} < U < u_{1-\frac{\alpha}{2}})=1-\alpha\)，
注意\(-u_{1-\frac{\alpha}{2}} = u_{\frac{\alpha}{2}}\)，
有\[
	P(-u_{1-\frac{\alpha}{2}} < U < u_{1-\frac{\alpha}{2}}) = 1-\alpha.
\]

由不等式\[
-u_{1-\frac{\alpha}{2}} < \U < u_{1-\frac{\alpha}{2}}
\]解得等价的不等式\[
	\overline{X} - u_{1-\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}}
	< \mu <
	\overline{X} + u_{1-\frac{\alpha}{2}} \frac{\sigma_0}{\sqrt{n}}.
	\qedhere
\]
\end{proof}
\end{example}

\begin{example}
\(\sigma^2\)未知，则总体均值\(\mu\)的置信区间为\[
	\left( \overline{X} - t_{1-\frac{\alpha}{2}}(n-1) \frac{S}{\sqrt{n}},
	\overline{X} + t_{1-\frac{\alpha}{2}}(n-1) \frac{S}{\sqrt{n}} \right).
\]
\end{example}

\begin{example}
\(\mu\)未知，则总体方差\(\sigma^2\)的置信区间为\[
	\left( \frac{(n-1)S^2}{\chi_{1-\frac{\alpha}{2}}^2(n-1)},
	\frac{(n-1)S^2}{\chi_{\frac{\alpha}{2}}^2(n-1)} \right).
\]
\end{example}

\subsection{两个正态总体下的参数的置信区间}
本小节中，设有两个正态总体\(X \sim N(\mu_1,\sigma_1^2)\)，
\(Y \sim N(\mu_2,\sigma_2^2)\).
\(\AutoTuple{X}{n_1}\)和\(\AutoTuple{Y}{n_2}\)是分别来自\(X\)和\(Y\)的两个独立样本.
其样本均值和样本方差分别为\[
	\overline{X} = \frac{1}{n_1} \sum_{i=1}^{n_1} X_i,
	\quad
	\overline{Y} = \frac{1}{n_2} \sum_{i=1}^{n_2} Y_i,
	\]\[
	S_1^2 = \frac{1}{n_1-1} \sum_{i=1}^{n_1} (X_i-\overline{X})^2, \quad
	S_2^2 = \frac{1}{n_2-1} \sum_{i=1}^{n_2} (Y_i-\overline{Y})^2.
\]

\begin{example}
\(\sigma_1^2\)、\(\sigma_2^2\)都已知，
则总体均值差\(\mu_1-\mu_2\)的置信区间为\[
	\left(\overline{X}-\overline{Y}-\delta,\ \overline{X}-\overline{Y}+\delta\right),
\]
其中\[
	\delta = u_{1-\frac{\alpha}{2}} \sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}.
\]
\end{example}

\begin{example}
\(\sigma_1^2\)与\(\sigma_2^2\)都未知，
但\(\sigma_1^2=\sigma_2^2=\sigma^2\)，
则\(\mu_1-\mu_2\)的置信区间为\[
	\left(\overline{X}-\overline{Y}-\delta,\ \overline{X}-\overline{Y}+\delta\right),
\]
其中\[
	\delta = t_{1-\frac{\alpha}{2}} S_w \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}.
\]
\end{example}

\begin{example}
当\(\mu_1\)、\(\mu_2\)、\(\sigma_1^2\)、\(\sigma_2^2\)都未知时，
总体方差比\(\sigma_1^2/\sigma_2^2\)的置信区间为\[
	\left(
		\frac{S_1^2}{S_2^2 F_{1-\frac{\alpha}{2}}},
		\frac{S_1^2}{S_2^2 F_{\frac{\alpha}{2}}}
	\right).
\]
\end{example}

\subsection{自然指数分布族分布均值参数的置信区间}
如果总体\(X\)不是服从正态分布，那么样本函数的分布是难于确定的.
这样求总体分布中未知参数的置信区间就比较困难.
但当样本容量很大时，我们可以根据中心极限定理近似地求出置信区间.

设总体\(X\)服从某个分布，分布函数为\(F(x,\theta)\)，
其中\(\theta\)是未知参数，
则总体均值\(E(X)=m(\theta)\)和总体方差\(D(X)=\sigma^2(\theta)\)都应该是\(\theta\)的函数.
抽取样本\(\AutoTuple{X}{n}\)，由于\(X_i\ (i=1,2,\dotsc,n)\)与总体独立同分布，
由中心极限定理，当\(n\)充分大时（一般要求\(n \geq 50\)），样本函数\[
	U = \frac{\sum_{i=1}^n{X_i} - n m(\theta)}{\sqrt{n} \sigma(\theta)}
	= \frac{\overline{X} - m(\theta)}{\sigma(\theta) / \sqrt{n}}
\]近似地服从标准正态分布\(N(0,1)\).
对于给定的置信度\(1-\alpha\)，有\[
	P(\abs{U}<u_{1-\frac{\alpha}{2}})
	= P\left(
		\abs{\frac{\overline{X} - m(\theta)}{\sigma(\theta) / \sqrt{n}}}<u_{1-\frac{\alpha}{2}}
	\right)
	\approx 1-\alpha.
\]
若能从不等式\[
	\abs{\frac{\overline{X} - m(\theta)}{\sigma(\theta) / \sqrt{n}}}<u_{1-\frac{\alpha}{2}}
\]
解得等价的不等式\[
	\hat{\theta}_1 < \theta < \hat{\theta}_2,
\]
则\((\hat{\theta}_1, \hat{\theta}_2)\)就是\(\theta\)的近似的\(1-\alpha\)置信区间.

对于非正态总体\(X\)，较常见的是\(X\)服从自然指数分布族分布.
常见的参数情形是均值参数，则可从不等式\[
	\abs{\frac{\overline{X} - m}{\sqrt{V(m) / n}}}<u_{1-\frac{\alpha}{2}}
\]
解得\[
	\hat{m}_1 < m < \hat{m}_2.
\]

\subsection{单侧置信限}
\begin{definition}
设总体\(X\)的分布函数\(F(x,\theta)\)中含有未知参数\(\theta\)，
\(\AutoTuple{X}{n}\)是来自总体\(X\)的一个样本.

若存在统计量\(\hat{\theta}_1(\AutoTuple{X}{n})\)使得\[
	P(\theta>\hat{\theta}_1)=1-\alpha,
\]
则称“\(\hat{\theta}_1\)是参数\(\theta\)的置信度为\(1-\alpha\)的\DefineConcept{单侧置信下限}”.

若存在统计量\(\hat{\theta}_2(\AutoTuple{X}{n})\)使得\[
	P(\theta<\hat{\theta}_2)=1-\alpha,
\]
则称“\(\hat{\theta}_2\)是参数\(\theta\)的置信度为\(1-\alpha\)的\DefineConcept{单侧置信上限}”.
\end{definition}

\section{本章总结}
\begin{table}[ht]
	\centering
	\begin{tabular}{*5{|c}|}
		\hline
		总体分布
			& 已知量
			& 未知量
			& 矩估计量
			& 极大似然估计量
		\\ \hline
		任何分布
			&
			& \(\mu,\sigma^2\)
			& \(\begin{aligned}
					\hat{\mu} &= \overline{X}, \\
					\hat{\sigma^2} &= B_2
				\end{aligned}\)
			&
		\\ \hline
		正态分布\newline\(N(\mu,\sigma^2)\)
			&
			& \(\mu,\sigma^2\)
			& 同上
			& 同左
		\\ \hline
		二项分布\newline\(B(N,p)\)
			& \(N\)
			& \(p\)
			& \(\begin{aligned}
					\hat{p} &= \frac{\overline{X}}{N}, \\
					\hat{\sigma^2} &= \overline{X} - \frac{\overline{X}^2}{N}
				\end{aligned}\)
			& \(\hat{p} = \frac{\overline{X}}{N}\)
		\\ \hline
		泊松分布\newline\(P(\lambda)\)
			&
			& \(\lambda\)
			& \(\hat{\lambda} = \overline{X}\)
			& 同左
		\\ \hline
		几何分布\newline\(G(p)\)
			&
			& \(p\)
			& \(\hat{p} = \frac{1}{\overline{X}}\)
			& \(\begin{aligned}
					\hat{p} &= \frac{1}{\overline{X}}, \\
					\hat{\sigma^2} &= \overline{X}^2-\overline{X}
				\end{aligned}\)
		\\ \hline
		指数分布\newline\(e(\lambda)\)
			&
			& \(\lambda\)
			& \(\hat{\lambda} = \frac{1}{\overline{X}}\)
			& 同左
		\\ \hline
		均匀分布\newline\(U(\theta_1,\theta_2)\)
			&
			& \(\theta_1,\theta_2\)
			& \(\begin{aligned}
					\hat{\theta_1} &= \overline{X} - \sqrt{3 B_2}, \\
					\hat{\theta_2} &= \overline{X} + \sqrt{3 B_2}
				\end{aligned}\)
			& \(\begin{aligned}
					\hat{\theta_1} &= \min_{1\leq i\leq n} X_i, \\
					\hat{\theta_2} &= \max_{1\leq i\leq n} X_i
				\end{aligned}\)
		\\ \hline
	\end{tabular}
	\caption{常见分布的参数估计}
\end{table}
